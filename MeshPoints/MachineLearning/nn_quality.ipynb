{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0ccc2fee2d5adce89579dcecef6a2a73d27aad38392c686d1718faba1504ffcdf",
   "display_name": "Python 3.7.4 64-bit ('masterMLvenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          x0        y0        x1        y1        x2        y2        x3  \\\n",
       "6   1.119785  0.039213  0.332836  0.544491  0.213457  1.025150 -0.627492   \n",
       "18  0.915908  0.596912  0.923602  0.918246  0.385590  1.001687 -0.215460   \n",
       "43  0.569095 -0.069833  0.540902  0.789540 -0.305556  1.099521 -0.724683   \n",
       "44  0.895173  0.048712  0.665237  0.560939  0.047844  0.791258 -0.853415   \n",
       "47  0.867850 -0.215618  0.450728  0.340656  0.176948  1.041175 -0.821253   \n",
       "\n",
       "          y3        x4        y4  ...        x6        y6        x7        y7  \\\n",
       "6   0.987861 -0.688993  0.155813  ...  0.262866 -1.423671  0.590690 -0.201720   \n",
       "18  1.045480 -0.622458  0.215055  ...  0.083952 -1.376717  0.682998 -0.082009   \n",
       "43  1.202892 -0.903440 -0.083918  ... -0.232435 -1.069934  0.810941 -0.581951   \n",
       "44  1.197531 -0.898977 -0.162231  ... -0.130734 -0.771453  0.424269 -0.463431   \n",
       "47  0.722107 -0.969543 -0.037427  ...  0.128191 -1.308836  0.628338 -0.942034   \n",
       "\n",
       "         ix0       iy0       ix1       iy1       ix2       iy2  \n",
       "6  -0.067951 -0.166750 -0.170636  0.513827  0.681104  0.127328  \n",
       "18  0.020068  0.519190  0.477077  0.379075  0.333169 -0.266751  \n",
       "43 -0.510538  0.435534 -0.048890  0.367831  0.152312 -0.534331  \n",
       "44 -0.475692  0.415051 -0.198221 -0.166352  0.366860  0.154225  \n",
       "47 -0.204869  0.082956 -0.090193  0.547877  0.330127 -0.300817  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x0</th>\n      <th>y0</th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>x4</th>\n      <th>y4</th>\n      <th>...</th>\n      <th>x6</th>\n      <th>y6</th>\n      <th>x7</th>\n      <th>y7</th>\n      <th>ix0</th>\n      <th>iy0</th>\n      <th>ix1</th>\n      <th>iy1</th>\n      <th>ix2</th>\n      <th>iy2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>1.119785</td>\n      <td>0.039213</td>\n      <td>0.332836</td>\n      <td>0.544491</td>\n      <td>0.213457</td>\n      <td>1.025150</td>\n      <td>-0.627492</td>\n      <td>0.987861</td>\n      <td>-0.688993</td>\n      <td>0.155813</td>\n      <td>...</td>\n      <td>0.262866</td>\n      <td>-1.423671</td>\n      <td>0.590690</td>\n      <td>-0.201720</td>\n      <td>-0.067951</td>\n      <td>-0.166750</td>\n      <td>-0.170636</td>\n      <td>0.513827</td>\n      <td>0.681104</td>\n      <td>0.127328</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.915908</td>\n      <td>0.596912</td>\n      <td>0.923602</td>\n      <td>0.918246</td>\n      <td>0.385590</td>\n      <td>1.001687</td>\n      <td>-0.215460</td>\n      <td>1.045480</td>\n      <td>-0.622458</td>\n      <td>0.215055</td>\n      <td>...</td>\n      <td>0.083952</td>\n      <td>-1.376717</td>\n      <td>0.682998</td>\n      <td>-0.082009</td>\n      <td>0.020068</td>\n      <td>0.519190</td>\n      <td>0.477077</td>\n      <td>0.379075</td>\n      <td>0.333169</td>\n      <td>-0.266751</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.569095</td>\n      <td>-0.069833</td>\n      <td>0.540902</td>\n      <td>0.789540</td>\n      <td>-0.305556</td>\n      <td>1.099521</td>\n      <td>-0.724683</td>\n      <td>1.202892</td>\n      <td>-0.903440</td>\n      <td>-0.083918</td>\n      <td>...</td>\n      <td>-0.232435</td>\n      <td>-1.069934</td>\n      <td>0.810941</td>\n      <td>-0.581951</td>\n      <td>-0.510538</td>\n      <td>0.435534</td>\n      <td>-0.048890</td>\n      <td>0.367831</td>\n      <td>0.152312</td>\n      <td>-0.534331</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.895173</td>\n      <td>0.048712</td>\n      <td>0.665237</td>\n      <td>0.560939</td>\n      <td>0.047844</td>\n      <td>0.791258</td>\n      <td>-0.853415</td>\n      <td>1.197531</td>\n      <td>-0.898977</td>\n      <td>-0.162231</td>\n      <td>...</td>\n      <td>-0.130734</td>\n      <td>-0.771453</td>\n      <td>0.424269</td>\n      <td>-0.463431</td>\n      <td>-0.475692</td>\n      <td>0.415051</td>\n      <td>-0.198221</td>\n      <td>-0.166352</td>\n      <td>0.366860</td>\n      <td>0.154225</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.867850</td>\n      <td>-0.215618</td>\n      <td>0.450728</td>\n      <td>0.340656</td>\n      <td>0.176948</td>\n      <td>1.041175</td>\n      <td>-0.821253</td>\n      <td>0.722107</td>\n      <td>-0.969543</td>\n      <td>-0.037427</td>\n      <td>...</td>\n      <td>0.128191</td>\n      <td>-1.308836</td>\n      <td>0.628338</td>\n      <td>-0.942034</td>\n      <td>-0.204869</td>\n      <td>0.082956</td>\n      <td>-0.090193</td>\n      <td>0.547877</td>\n      <td>0.330127</td>\n      <td>-0.300817</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df = pd.read_csv('data/8-gon-gh-dataset.csv')\n",
    "\n",
    "good_data = pd.isnull(df['dum1'])\n",
    "\n",
    "dataset = df[good_data].dropna(axis=1, how='all')\n",
    "\n",
    "# Split dataset into 70/15/15 training/validation/test\n",
    "train = dataset.sample(frac=0.85)\n",
    "test = dataset.drop(train.index)\n",
    "\n",
    "# Split dataset into features and labels; last 4 (grid scores)\n",
    "train_features = train.iloc[:, 1:]\n",
    "train_labels = train.iloc[:, :1]\n",
    "\n",
    "test_features = test.iloc[:, 1:]\n",
    "test_labels = test.iloc[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os, datetime\n",
    "\n",
    "model_path = \"model/mesh-quality-8gon-small\"\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5000\n",
    "INITIAL_LEARNING_RATE = 1e-1\n",
    "\n",
    "def model_setup():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(22,)),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_features, train_label, model_epochs=EPOCHS, model_batch_size=BATCH_SIZE, learning_rate=INITIAL_LEARNING_RATE):\n",
    "    # Callbacks\n",
    "    # logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    # tensorboard = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=EPOCHS//5, min_delta=0.0001)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    decay_steps= 10_000\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        learning_rate, \n",
    "        decay_steps, \n",
    "        1e-2\n",
    "        )\n",
    "\n",
    "    # Initialize model\n",
    "    model.compile(loss=tf.losses.MeanAbsoluteError(),\n",
    "                optimizer=tf.optimizers.Adam(\n",
    "                learning_rate=lr_schedule\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    # Train model and write progress to history (for graphing)\n",
    "    history = model.fit(train_features,\n",
    "                        train_labels,\n",
    "                        epochs=model_epochs,\n",
    "                        batch_size=model_batch_size,\n",
    "                        validation_split=0.18,\n",
    "                        verbose=2,\n",
    "                        callbacks=[checkpoint, early_stopping],\n",
    "                        )\n",
    "    return history\n",
    "\n",
    "model = model_setup()\n",
    "model.summary()\n",
    "history = train_model(model, train_features, train_labels)\n",
    "\n",
    "# ======================\n",
    "#       EVALUATION\n",
    "# ======================\n",
    "train_acc = model.evaluate(\n",
    "    train_features, train_labels, verbose=0)\n",
    "test_acc = model.evaluate(\n",
    "    test_features, test_labels, verbose=0)\n",
    "print('Training data loss: %.3f, Test data loss: %.3f' %\n",
    "        (train_acc, test_acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}