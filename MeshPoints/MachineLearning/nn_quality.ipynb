{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0ccc2fee2d5adce89579dcecef6a2a73d27aad38392c686d1718faba1504ffcdf",
   "display_name": "Python 3.7.4 64-bit ('masterMLvenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/8-gon-gh-dataset.csv')\n",
    "\n",
    "good_data = pd.isnull(df['dum1'])\n",
    "\n",
    "dataset = df[good_data].dropna(axis=1, how='all')\n",
    "\n",
    "# Split dataset into 70/15/15 training/validation/test\n",
    "train = dataset.sample(frac=0.85)\n",
    "test = dataset.drop(train.index)\n",
    "\n",
    "# Split dataset into features and labels; last 4 (grid scores)\n",
    "train_features = train.iloc[:, 1:]\n",
    "train_labels = train.iloc[:, :1]\n",
    "\n",
    "test_features = test.iloc[:, 1:]\n",
    "test_labels = test.iloc[:, :1]\n",
    "\n",
    "train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os, datetime\n",
    "\n",
    "model_path = \"model/mesh-quality-8gon-small-1\"\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 1000\n",
    "INITIAL_LEARNING_RATE = 1e-1\n",
    "\n",
    "def model_setup():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(22,)),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_features, train_label, model_epochs=EPOCHS, model_batch_size=BATCH_SIZE, learning_rate=INITIAL_LEARNING_RATE):\n",
    "    # Callbacks\n",
    "    # logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    # tensorboard = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=EPOCHS//10, min_delta=0.0001)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    decay_steps= 10_000\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        learning_rate, \n",
    "        decay_steps, \n",
    "        1e-2\n",
    "        )\n",
    "\n",
    "    # Initialize model\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(\n",
    "                learning_rate=3e-4\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    # Train model and write progress to history (for graphing)\n",
    "    history = model.fit(train_features,\n",
    "                        train_labels,\n",
    "                        epochs=model_epochs,\n",
    "                        batch_size=model_batch_size,\n",
    "                        validation_split=0.18,\n",
    "                        verbose=2,\n",
    "                        callbacks=[checkpoint, early_stopping],\n",
    "                        )\n",
    "    return history\n",
    "\n",
    "model = model_setup()\n",
    "model.summary()\n",
    "history = train_model(model, train_features, train_labels)\n",
    "\n",
    "# ======================\n",
    "#       EVALUATION\n",
    "# ======================\n",
    "train_acc = model.evaluate(\n",
    "    train_features, train_labels, verbose=0)\n",
    "test_acc = model.evaluate(\n",
    "    test_features, test_labels, verbose=0)\n",
    "print('Training data loss: %.3f, Test data loss: %.3f' %\n",
    "        (train_acc, test_acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test = [0.91484244,  0.00551026,  0.77336363,  0.79442204,\n",
    "        0.06119724,  0.99685841, -0.48074287,  0.39218434, -0.9447753 ,\n",
    "        0.17089053, -0.75703453, -0.93550632,  0.08711492, -0.97169181,\n",
    "        0.73734201, -0.82820086, -0.25672259, -0.23196948,  0.22315476,\n",
    "        0.27751235,  0.34114631, -0.34976791]\n",
    "min_test = [1.4360157 , -0.28543287,  0.89610679,  0.17926611,\n",
    "        0.00860781,  1.36589249, -0.40462255,  0.49788496, -0.97526413,\n",
    "       -0.33061286, -0.70153368, -0.37833038,  0.43591692, -0.52997161,\n",
    "        0.71686403, -0.25175814, -0.41137586, -0.18525747,  0.16669735,\n",
    "        0.68101452,  0.66109099,  0.03499002]\n",
    "test_label = 0.832\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('data/quality-test-big-dataset.csv')\n",
    "good_data = pd.isnull(test_df['dum1'])\n",
    "\n",
    "dataset = test_df[good_data].dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "pred_model = tf.keras.models.load_model(\"model/mesh-quality-8gon-small-1\")\n",
    "features = np.expand_dims(max_test, axis=0)\n",
    "features_min = np.expand_dims(min_test, axis=0)\n",
    "\n",
    "min_pred = pred_model(features).numpy()\n",
    "max_pred = pred_model(features_min).numpy()\n",
    "# dataset['avgQuality'].idxmin()\n",
    "# dataset.loc[5079].values\n",
    "# dataset.head(100)\n",
    "min_pred, max_pred"
   ]
  },
  {
   "source": [
    "max_qual = 0.845 \n",
    "min_qual = 0.401\n",
    "\n",
    "0.6430032\n",
    "0.6430032\n",
    "0.6429662"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}